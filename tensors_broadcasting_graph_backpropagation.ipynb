{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zA1O5zIVfQwX"
   },
   "source": [
    "# Introduction\n",
    "In this notebook we will explore the idea of tensors, creating them, indexing and broadcasting. We will use pytorch - however if you know these concepts from numpy, you should be able to directly apply them in pytorch. We will also put them on a GPU and perform some simple calculations. Finally we will touch very briefly on gradient calculation - a concept essential in deep learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uuaA-RM1F-lh"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-WMXG3KXtXnr"
   },
   "source": [
    "## ONLY FOLLOW THIS IF YOU ARE ON COLAB\n",
    "Before we begin change the Runtime to use a GPU: Click on 'Runtime' --> 'Change Runtime Type' -> from 'Hardware Accelerator' select GPU if it is not already selected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U__sxNQxtxO2"
   },
   "source": [
    "Now lets check CUDA version and check pytorch installation, run the cells below in turn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OnIhaQYIt5m8",
    "outputId": "fdb1fefa-bd6b-4ab2-f8e9-eaa5653b69f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2025 NVIDIA Corporation\n",
      "Built on Wed_Apr__9_19:24:57_PDT_2025\n",
      "Cuda compilation tools, release 12.9, V12.9.41\n",
      "Build cuda_12.9.r12.9/compiler.35813241_0\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "udtlf7qht7bS",
    "outputId": "6a17cc2d-0d1f-407e-8229-94d256d41424"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun 19 23:06:37 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 575.51.03              Driver Version: 575.51.03      CUDA Version: 12.9     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 2080 Ti     Off |   00000000:1A:00.0 Off |                  N/A |\n",
      "| 31%   36C    P0             47W /  250W |       1MiB /  11264MiB |      1%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  NVIDIA GeForce RTX 2080 Ti     Off |   00000000:1B:00.0 Off |                  N/A |\n",
      "| 30%   32C    P8             18W /  250W |       1MiB /  11264MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   2  NVIDIA GeForce RTX 2080 Ti     Off |   00000000:3D:00.0 Off |                  N/A |\n",
      "| 30%   30C    P8             20W /  250W |       1MiB /  11264MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   3  NVIDIA GeForce RTX 2080 Ti     Off |   00000000:3E:00.0 Off |                  N/A |\n",
      "| 30%   34C    P8              1W /  250W |       1MiB /  11264MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   4  NVIDIA GeForce RTX 2080 Ti     Off |   00000000:88:00.0 Off |                  N/A |\n",
      "| 30%   30C    P8              7W /  250W |       1MiB /  11264MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   5  NVIDIA GeForce RTX 2080 Ti     Off |   00000000:89:00.0 Off |                  N/A |\n",
      "| 30%   32C    P8             21W /  250W |       1MiB /  11264MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   6  NVIDIA GeForce RTX 2080 Ti     Off |   00000000:B1:00.0 Off |                  N/A |\n",
      "| 30%   32C    P8              2W /  250W |       1MiB /  11264MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   7  NVIDIA GeForce RTX 2080 Ti     Off |   00000000:B2:00.0 Off |                  N/A |\n",
      "| 22%   32C    P8             23W /  250W |       1MiB /  11264MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GMtjp8-380ye"
   },
   "source": [
    "You should see that nvcc - cuda compiler has version 10.0 or later and that one GPU is present in the table above, for instance a Tesla K80. Now let's check if pytorch is already installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fgdbq7oX9EjV",
    "outputId": "a601e7ad-b56d-4e45-8304-b0651c7e648b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK we have pytorch installed\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "if torch is not None:\n",
    "  print(\"OK we have pytorch installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "j4GB6I9EgI2T",
    "outputId": "1b79a4dd-bf32-4b51-cd28-cd0416330eb1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.8.0a0+5228986c39.nv25.05'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7kRbQ9tJ9IEn"
   },
   "source": [
    "If the cell above failed and did not print 'OK we have pytorch installed' there is a problem --> Talk to Wojtek"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P37Z4VS_GGi7"
   },
   "source": [
    "#Tensors\n",
    "In this section we will play a bit with pytorch tensors. If you used numpy before this will be very familiar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "_1fTMAUz0d4f"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End setup section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k7ZQCHBeLPTA"
   },
   "source": [
    "# Declaring Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P0FojOEl-WH4"
   },
   "source": [
    "We can declare tensors from lists, numpy arrays, other tensors, or by calling pytorch functions which initialize tensors to certain values (e.g. random, zeros, fill values etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o2qYXIzs1aZT",
    "outputId": "231cd07c-0259-481a-d308-50e93ecc2e33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Declared tensors:\n",
      "a: tensor([0, 1, 2])\n",
      "a_float: tensor([0., 1., 2.])\n",
      "b: tensor([[[-3.7447e-01, -9.9400e-01, -1.5016e+00,  7.0245e-01,  1.1155e+00],\n",
      "         [-2.1293e-01, -3.2859e-01, -9.4396e-01,  8.5166e-02,  4.3908e-01],\n",
      "         [ 1.5226e-01,  9.9637e-01, -1.2964e+00,  2.3695e+00,  2.3720e-01],\n",
      "         [-1.3802e+00,  6.8036e-01, -4.8345e-01,  3.6800e-01, -1.2650e+00]],\n",
      "\n",
      "        [[-2.7476e-01,  1.5515e-01,  8.3542e-01,  1.2632e+00, -1.3439e+00],\n",
      "         [ 1.2112e+00, -3.3643e-01,  4.0794e-01, -3.1471e-02,  8.4263e-01],\n",
      "         [ 1.6233e+00, -2.1729e+00, -2.1184e-02,  1.6371e+00, -1.9692e+00],\n",
      "         [-2.3548e+00,  1.6167e-01, -6.8759e-01,  8.0773e-01,  7.7540e-01]],\n",
      "\n",
      "        [[-4.6922e-01, -1.1071e-03,  9.6738e-02, -4.5349e-01,  5.1323e-01],\n",
      "         [-8.5086e-03,  1.7804e+00,  1.7580e-01, -7.7057e-01, -2.4897e+00],\n",
      "         [-5.3934e-01,  9.8608e-01, -1.7748e+00,  3.3204e-01, -2.6887e+00],\n",
      "         [ 6.6180e-02,  1.2931e-01,  1.1768e+00, -6.4278e-02, -7.4294e-01]]],\n",
      "       dtype=torch.float64)\n",
      "c: tensor([[[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]]])\n",
      "d: tensor([[[-1.2072,  1.9653, -1.0131,  1.8401,  1.7137],\n",
      "         [ 0.6784, -1.0267, -0.2639,  0.6028,  0.5417],\n",
      "         [ 0.6343, -0.9057, -0.9308, -0.0703,  0.0097],\n",
      "         [-0.3083,  0.2804, -1.2545, -0.4413,  1.0364]],\n",
      "\n",
      "        [[-0.4068,  1.1292,  0.1930, -0.2079, -0.1137],\n",
      "         [ 1.5263,  3.1920,  1.4617, -0.5132,  1.0130],\n",
      "         [ 1.2958, -1.0749, -1.5454, -0.6600, -0.5507],\n",
      "         [ 0.0956, -0.8913, -0.3922,  1.3861,  1.1941]],\n",
      "\n",
      "        [[ 0.2017, -1.6791,  0.6049, -0.0327,  0.5645],\n",
      "         [-0.7277, -1.5018, -0.1282, -1.0920, -0.8009],\n",
      "         [-0.6736, -2.0098,  0.0628, -0.8293, -0.2832],\n",
      "         [ 0.5807,  0.1791,  1.3265, -0.1233,  0.7782]]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([0, 1, 2])\n",
    "a_float=torch.tensor([0.0,1.0,2.0])\n",
    "b_np=np.random.randn(3,4,5)\n",
    "b=torch.tensor(b_np)\n",
    "c=torch.zeros(3,4,5)\n",
    "d=torch.randn(3,4,5)\n",
    "print(\"Declared tensors:\")\n",
    "print(\"a: {}\".format(a))\n",
    "print(\"a_float: {}\".format(a_float))\n",
    "print(\"b: {}\".format(b))\n",
    "print(\"c: {}\".format(c))\n",
    "print(\"d: {}\".format(d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HDNuaXMY3OVC"
   },
   "source": [
    "## Indexing tensors\n",
    "indexing works almost identically to numpy indexing including slicing and fancy indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HQWt3JpB3Ef4",
    "outputId": "9c1d3db0-4706-47e7-e254-968a84213c9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1.2072)\n",
      "tensor([[[ 0.6784, -1.0267, -0.2639,  0.6028],\n",
      "         [-0.3083,  0.2804, -1.2545, -0.4413]],\n",
      "\n",
      "        [[ 1.5263,  3.1920,  1.4617, -0.5132],\n",
      "         [ 0.0956, -0.8913, -0.3922,  1.3861]],\n",
      "\n",
      "        [[-0.7277, -1.5018, -0.1282, -1.0920],\n",
      "         [ 0.5807,  0.1791,  1.3265, -0.1233]]])\n"
     ]
    }
   ],
   "source": [
    "print(d[0,0,0])\n",
    "print(d[:,1::2,:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FRxSauKiEFWy"
   },
   "source": [
    "You may even use tensors to index tensors,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EwQyIjK_EMFo",
    "outputId": "f986b680-b0e9-44fc-8d08-3294960685d9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.2072,  3.1920,  0.0628])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[a,a,a]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gr4cGXeKEvwC"
   },
   "source": [
    "But - if you do that the tensor you are using to index should be integer type (or long integer). The cell below illustrates this - it will raise `IndexError`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 162
    },
    "id": "1YP9jFPvFEg4",
    "outputId": "722069ac-40e2-4048-bb1c-7bc9a1640e94"
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tensors used as indices must be long, int, byte or bool tensors",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43md\u001b[49m\u001b[43m[\u001b[49m\u001b[43ma_float\u001b[49m\u001b[43m,\u001b[49m\u001b[43ma_float\u001b[49m\u001b[43m,\u001b[49m\u001b[43ma_float\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[31mIndexError\u001b[39m: tensors used as indices must be long, int, byte or bool tensors"
     ]
    }
   ],
   "source": [
    "d[a_float,a_float,a_float]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pW9WwioZ3aWg"
   },
   "source": [
    "There is one common pitfall - when you index a particular position in a tensor - you get a '0 dimensional' tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oCdZne_8Eu7D",
    "outputId": "22aa34a2-2784-43cb-d8ea-c1bb7fdd7ae7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.1920)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[1,1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uZznLvFkKwgh",
    "outputId": "06431437-9ba0-4bb8-a1d7-0c8d83c13b16"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[1,1,1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z5DPoaYwK2H4"
   },
   "source": [
    "To get the actual number we need to use `item()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ua-IwOzw3FcJ",
    "outputId": "9434d2b4-fc57-4f65-b64b-00ccb1107b9e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.1919989585876465"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[1,1,1].item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AobtyN1n3nZK"
   },
   "source": [
    "Pay attention to the datatype of the tensor. Generally we want float32 type tensors for data in deep learning and long integer tensors for labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HXSAGQgV3KI4",
    "outputId": "20668066-4020-4282-9714-6043d4c4250b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64\n",
      "torch.float64\n"
     ]
    }
   ],
   "source": [
    "print(a.dtype)\n",
    "print(b.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MiuIqFOzAyJY"
   },
   "source": [
    "##Using GPUs\n",
    "We'll now send some data to the GPU and perform some example calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "dJdKQtwfBEp7"
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    d=d.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oJADPCyBBLNU",
    "outputId": "18dc0443-210d-4b2b-a976-232acee3a223"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.2072,  1.9653, -1.0131,  1.8401,  1.7137],\n",
      "         [ 0.6784, -1.0267, -0.2639,  0.6028,  0.5417],\n",
      "         [ 0.6343, -0.9057, -0.9308, -0.0703,  0.0097],\n",
      "         [-0.3083,  0.2804, -1.2545, -0.4413,  1.0364]],\n",
      "\n",
      "        [[-0.4068,  1.1292,  0.1930, -0.2079, -0.1137],\n",
      "         [ 1.5263,  3.1920,  1.4617, -0.5132,  1.0130],\n",
      "         [ 1.2958, -1.0749, -1.5454, -0.6600, -0.5507],\n",
      "         [ 0.0956, -0.8913, -0.3922,  1.3861,  1.1941]],\n",
      "\n",
      "        [[ 0.2017, -1.6791,  0.6049, -0.0327,  0.5645],\n",
      "         [-0.7277, -1.5018, -0.1282, -1.0920, -0.8009],\n",
      "         [-0.6736, -2.0098,  0.0628, -0.8293, -0.2832],\n",
      "         [ 0.5807,  0.1791,  1.3265, -0.1233,  0.7782]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2uWQ1VqmMsSX"
   },
   "source": [
    "We can now perform some calculations which will be performed by the GPU. For instance element-wise addition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2QpQPBc_NFoa",
    "outputId": "78ac2e9a-8ea8-415a-8b51-7364e5361c0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-2.4143,  3.9306, -2.0263,  3.6801,  3.4273],\n",
      "         [ 1.3568, -2.0534, -0.5279,  1.2056,  1.0833],\n",
      "         [ 1.2685, -1.8113, -1.8616, -0.1407,  0.0194],\n",
      "         [-0.6166,  0.5607, -2.5091, -0.8826,  2.0728]],\n",
      "\n",
      "        [[-0.8136,  2.2583,  0.3861, -0.4157, -0.2274],\n",
      "         [ 3.0527,  6.3840,  2.9235, -1.0264,  2.0260],\n",
      "         [ 2.5915, -2.1497, -3.0909, -1.3201, -1.1013],\n",
      "         [ 0.1912, -1.7825, -0.7843,  2.7723,  2.3882]],\n",
      "\n",
      "        [[ 0.4035, -3.3582,  1.2097, -0.0653,  1.1291],\n",
      "         [-1.4555, -3.0035, -0.2563, -2.1840, -1.6019],\n",
      "         [-1.3472, -4.0196,  0.1255, -1.6587, -0.5664],\n",
      "         [ 1.1614,  0.3582,  2.6529, -0.2467,  1.5564]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "e=d+d\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NFMKEgJ9NLBg"
   },
   "source": [
    "As you can see above the output stays on GPU. You can't perform operations on tensors residing on different devices, the next cell will fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 162
    },
    "id": "bTBwNNrqlUo3",
    "outputId": "ed82fb55-332f-4643-b8e1-8cd8b9ee9801"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mc\u001b[49m\u001b[43m+\u001b[49m\u001b[43md\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
     ]
    }
   ],
   "source": [
    "c+d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jVLYOLgloaiQ"
   },
   "source": [
    "##Tensor operations, shape and reshaping\n",
    "In the cells above we performed a element-wise addition using `+` -  but this is overloaded `add()` function. You can take a look at the available operations [here](https://pytorch.org/docs/stable/tensors.html#torch.Tensor). Most of the available operations have an in-place version - the convention is that the name of that operation ends with `_`. The output of these will be assigned to the tensor the operation is called on. This can save some memory but can be a bit [tricky](https://pytorch.org/docs/stable/notes/autograd.html#in-place-operations-with-autograd) if we use the tensor to calculate gradients. The cell below illustrates how to use both styles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ud_VOtvRqstV",
    "outputId": "fac80d27-3217-4d51-c68d-903d43102a21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_plus_d: tensor([[[-2.4143,  3.9306, -2.0263,  3.6801,  3.4273],\n",
      "         [ 1.3568, -2.0534, -0.5279,  1.2056,  1.0833],\n",
      "         [ 1.2685, -1.8113, -1.8616, -0.1407,  0.0194],\n",
      "         [-0.6166,  0.5607, -2.5091, -0.8826,  2.0728]],\n",
      "\n",
      "        [[-0.8136,  2.2583,  0.3861, -0.4157, -0.2274],\n",
      "         [ 3.0527,  6.3840,  2.9235, -1.0264,  2.0260],\n",
      "         [ 2.5915, -2.1497, -3.0909, -1.3201, -1.1013],\n",
      "         [ 0.1912, -1.7825, -0.7843,  2.7723,  2.3882]],\n",
      "\n",
      "        [[ 0.4035, -3.3582,  1.2097, -0.0653,  1.1291],\n",
      "         [-1.4555, -3.0035, -0.2563, -2.1840, -1.6019],\n",
      "         [-1.3472, -4.0196,  0.1255, -1.6587, -0.5664],\n",
      "         [ 1.1614,  0.3582,  2.6529, -0.2467,  1.5564]]], device='cuda:0')\n",
      "\n",
      "dcpy: tensor([[[-2.4143,  3.9306, -2.0263,  3.6801,  3.4273],\n",
      "         [ 1.3568, -2.0534, -0.5279,  1.2056,  1.0833],\n",
      "         [ 1.2685, -1.8113, -1.8616, -0.1407,  0.0194],\n",
      "         [-0.6166,  0.5607, -2.5091, -0.8826,  2.0728]],\n",
      "\n",
      "        [[-0.8136,  2.2583,  0.3861, -0.4157, -0.2274],\n",
      "         [ 3.0527,  6.3840,  2.9235, -1.0264,  2.0260],\n",
      "         [ 2.5915, -2.1497, -3.0909, -1.3201, -1.1013],\n",
      "         [ 0.1912, -1.7825, -0.7843,  2.7723,  2.3882]],\n",
      "\n",
      "        [[ 0.4035, -3.3582,  1.2097, -0.0653,  1.1291],\n",
      "         [-1.4555, -3.0035, -0.2563, -2.1840, -1.6019],\n",
      "         [-1.3472, -4.0196,  0.1255, -1.6587, -0.5664],\n",
      "         [ 1.1614,  0.3582,  2.6529, -0.2467,  1.5564]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "dcpy=d.clone()\n",
    "d_plus_d=d.add(d)\n",
    "\n",
    "dcpy.add_(dcpy)\n",
    "print(\"d_plus_d: {}\\n\\ndcpy: {}\".format(d_plus_d,dcpy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yJTX1jPfKWER"
   },
   "source": [
    "For future reference we will clone tensor d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "isaE7O95Ka75"
   },
   "outputs": [],
   "source": [
    "dcpy=d.clone()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8USAvewTuQ83"
   },
   "source": [
    "Often we will need to change shape of the tensor. We have two options to find a shape of a tensor `size()` and `shape`- these are completely equivalent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HJjVRbwokc8q",
    "outputId": "f7912d27-d08b-40a1-86ab-2617fbe9784f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4, 5])\n",
      "torch.Size([3, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "print(d.shape)\n",
    "print(d.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f89A2VAIk8HI"
   },
   "source": [
    "To change tensor shapes we have two options: `view` and `reshape`.  `view` as the name implies gives you a pointer to the same memory location but with adjusted 'strides' so that the shape is as you specify i.e. a new 'view' of the same data. On the other hand `reshape` will give you a view of a tensor, if it is possible (i.e. if the tensor's memory is contiguous), or a copy if it is not. As a rule of thumb avoid using `reshape`. If a copy of a tensor is needed with explicit new (contiguous) memory allocation use `clone`. The cells below give some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iOoX5mdfwuX5",
    "outputId": "6c0cb933-c504-4f44-ef7a-3eaaf42ac0eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.2072,  1.9653, -1.0131,  1.8401,  1.7137],\n",
      "         [ 0.6784, -1.0267, -0.2639,  0.6028,  0.5417],\n",
      "         [ 0.6343, -0.9057, -0.9308, -0.0703,  0.0097],\n",
      "         [-0.3083,  0.2804, -1.2545, -0.4413,  1.0364]],\n",
      "\n",
      "        [[-0.4068,  1.1292,  0.1930, -0.2079, -0.1137],\n",
      "         [ 1.5263,  3.1920,  1.4617, -0.5132,  1.0130],\n",
      "         [ 1.2958, -1.0749, -1.5454, -0.6600, -0.5507],\n",
      "         [ 0.0956, -0.8913, -0.3922,  1.3861,  1.1941]],\n",
      "\n",
      "        [[ 0.2017, -1.6791,  0.6049, -0.0327,  0.5645],\n",
      "         [-0.7277, -1.5018, -0.1282, -1.0920, -0.8009],\n",
      "         [-0.6736, -2.0098,  0.0628, -0.8293, -0.2832],\n",
      "         [ 0.5807,  0.1791,  1.3265, -0.1233,  0.7782]]], device='cuda:0')\n",
      "tensor([[-1.2072,  1.9653, -1.0131,  1.8401,  1.7137,  0.6784, -1.0267, -0.2639,\n",
      "          0.6028,  0.5417,  0.6343, -0.9057],\n",
      "        [-0.9308, -0.0703,  0.0097, -0.3083,  0.2804, -1.2545, -0.4413,  1.0364,\n",
      "         -0.4068,  1.1292,  0.1930, -0.2079],\n",
      "        [-0.1137,  1.5263,  3.1920,  1.4617, -0.5132,  1.0130,  1.2958, -1.0749,\n",
      "         -1.5454, -0.6600, -0.5507,  0.0956],\n",
      "        [-0.8913, -0.3922,  1.3861,  1.1941,  0.2017, -1.6791,  0.6049, -0.0327,\n",
      "          0.5645, -0.7277, -1.5018, -0.1282],\n",
      "        [-1.0920, -0.8009, -0.6736, -2.0098,  0.0628, -0.8293, -0.2832,  0.5807,\n",
      "          0.1791,  1.3265, -0.1233,  0.7782]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "lets unroll the first dimension of d and rearrange the last two dimensions.\n",
    "Giving -1 as a parameter, just like in numpy reshape,\n",
    "will figure out what the dimension ought to be\n",
    "'''\n",
    "d_unroll_reshape=d.view(5,-1)\n",
    "print(d)\n",
    "print(d_unroll_reshape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KVBg5bDDzp8B"
   },
   "source": [
    "As you can see pytorch figured out that the last dimension should be 12. Again beware - the tensors `d` and `d_unroll_reshape` share data. Let's modify one element in `d` and watch it change in `d_unroll_reshape`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xgdmtjdD0ulD",
    "outputId": "503c5553-1c11-4fe7-fea4-2ab7ce0318b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(42., device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "d[0,2,1]=42.0\n",
    "print(d_unroll_reshape[0,-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FEgFNOKo1LrX"
   },
   "source": [
    "Use `clone` if you want brand new memory for the tensor. You can of course stack the operations -e.g. view and then clone. Now changing one will not affect the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hh3hZPdt4k_i",
    "outputId": "30a3c6cd-50a3-4518-a412-d34dd208510d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(42., device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "d_unroll_reshape_cloned=d.view(5,-1).clone()\n",
    "d_unroll_reshape_cloned[0,-1]=1984.0\n",
    "print(d[0,2,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vCxxorwfyqDI"
   },
   "source": [
    "Some operations will make the tensor non-contiguous. For instance the transpose operation. The data in memory will not be touched, just the strides affected. This means that it is impossible to get a different view of the tensor. Transposing the last two dimensions:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xylwsQqVuAuw",
    "outputId": "e2488d1a-b9c4-4992-a178-88c990255a1f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.2072e+00,  6.7838e-01,  6.3427e-01, -3.0830e-01],\n",
       "         [ 1.9653e+00, -1.0267e+00,  4.2000e+01,  2.8037e-01],\n",
       "         [-1.0131e+00, -2.6393e-01, -9.3082e-01, -1.2545e+00],\n",
       "         [ 1.8401e+00,  6.0281e-01, -7.0335e-02, -4.4129e-01],\n",
       "         [ 1.7137e+00,  5.4167e-01,  9.6804e-03,  1.0364e+00]],\n",
       "\n",
       "        [[-4.0680e-01,  1.5263e+00,  1.2958e+00,  9.5622e-02],\n",
       "         [ 1.1292e+00,  3.1920e+00, -1.0749e+00, -8.9126e-01],\n",
       "         [ 1.9303e-01,  1.4617e+00, -1.5454e+00, -3.9217e-01],\n",
       "         [-2.0787e-01, -5.1322e-01, -6.6004e-01,  1.3861e+00],\n",
       "         [-1.1371e-01,  1.0130e+00, -5.5066e-01,  1.1941e+00]],\n",
       "\n",
       "        [[ 2.0174e-01, -7.2774e-01, -6.7360e-01,  5.8068e-01],\n",
       "         [-1.6791e+00, -1.5018e+00, -2.0098e+00,  1.7910e-01],\n",
       "         [ 6.0486e-01, -1.2817e-01,  6.2755e-02,  1.3265e+00],\n",
       "         [-3.2653e-02, -1.0920e+00, -8.2933e-01, -1.2333e-01],\n",
       "         [ 5.6453e-01, -8.0093e-01, -2.8319e-01,  7.7819e-01]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.transpose_(1,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2hoLsyl-DdMj"
   },
   "source": [
    "After the transpose the entries in a single 'row' in the above tensor are not 'neighbours' in memory - the two numbers in the column are - so we can not reshape the tensor easliy;\n",
    "This will fail:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 162
    },
    "id": "UNPMmFBoDNEd",
    "outputId": "e91d4c5b-c1ae-4c49-f02c-cb3f59ca3e5d"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m d_back_to_original_shape=\u001b[43md\u001b[49m\u001b[43m.\u001b[49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead."
     ]
    }
   ],
   "source": [
    "d_back_to_original_shape=d.view(3,4,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7tILqp6BE0a3"
   },
   "source": [
    "We need to copy the tensor to contiguous memory space and then we can reshape it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BR1nbD-NDW6i"
   },
   "outputs": [],
   "source": [
    "d_back_to_original_shape=d.contiguous().view(3,4,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YclGpIDTH-Lj"
   },
   "source": [
    "Back close to the start we made a copy of d naming it `dcpy`. Lets print it now alongside d. Notice the difference in the tensors after all these reshaping operations? Do you understand what happened?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BRaE4H4YFu7X",
    "outputId": "17e70c6d-3d3c-477c-8304-fa0a8bfa747e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dcpy: tensor([[[-1.2072,  1.9653, -1.0131,  1.8401,  1.7137],\n",
      "         [ 0.6784, -1.0267, -0.2639,  0.6028,  0.5417],\n",
      "         [ 0.6343, -0.9057, -0.9308, -0.0703,  0.0097],\n",
      "         [-0.3083,  0.2804, -1.2545, -0.4413,  1.0364]],\n",
      "\n",
      "        [[-0.4068,  1.1292,  0.1930, -0.2079, -0.1137],\n",
      "         [ 1.5263,  3.1920,  1.4617, -0.5132,  1.0130],\n",
      "         [ 1.2958, -1.0749, -1.5454, -0.6600, -0.5507],\n",
      "         [ 0.0956, -0.8913, -0.3922,  1.3861,  1.1941]],\n",
      "\n",
      "        [[ 0.2017, -1.6791,  0.6049, -0.0327,  0.5645],\n",
      "         [-0.7277, -1.5018, -0.1282, -1.0920, -0.8009],\n",
      "         [-0.6736, -2.0098,  0.0628, -0.8293, -0.2832],\n",
      "         [ 0.5807,  0.1791,  1.3265, -0.1233,  0.7782]]], device='cuda:0')\n",
      "d_back_to_original_shape: tensor([[[-1.2072e+00,  6.7838e-01,  6.3427e-01, -3.0830e-01,  1.9653e+00],\n",
      "         [-1.0267e+00,  4.2000e+01,  2.8037e-01, -1.0131e+00, -2.6393e-01],\n",
      "         [-9.3082e-01, -1.2545e+00,  1.8401e+00,  6.0281e-01, -7.0335e-02],\n",
      "         [-4.4129e-01,  1.7137e+00,  5.4167e-01,  9.6804e-03,  1.0364e+00]],\n",
      "\n",
      "        [[-4.0680e-01,  1.5263e+00,  1.2958e+00,  9.5622e-02,  1.1292e+00],\n",
      "         [ 3.1920e+00, -1.0749e+00, -8.9126e-01,  1.9303e-01,  1.4617e+00],\n",
      "         [-1.5454e+00, -3.9217e-01, -2.0787e-01, -5.1322e-01, -6.6004e-01],\n",
      "         [ 1.3861e+00, -1.1371e-01,  1.0130e+00, -5.5066e-01,  1.1941e+00]],\n",
      "\n",
      "        [[ 2.0174e-01, -7.2774e-01, -6.7360e-01,  5.8068e-01, -1.6791e+00],\n",
      "         [-1.5018e+00, -2.0098e+00,  1.7910e-01,  6.0486e-01, -1.2817e-01],\n",
      "         [ 6.2755e-02,  1.3265e+00, -3.2653e-02, -1.0920e+00, -8.2933e-01],\n",
      "         [-1.2333e-01,  5.6453e-01, -8.0093e-01, -2.8319e-01,  7.7819e-01]]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(\"dcpy: {}\".format(dcpy))\n",
    "print(\"d_back_to_original_shape: {}\".format(d_back_to_original_shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KYtt93NiG3Yn"
   },
   "source": [
    "# Broadcasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hrtNDEzZG66e"
   },
   "source": [
    "A very useful feature of numpy and torch tensors is the ability to broadcast. It is a mechanism where operations on pairs of tensors of different dimensionalities can be performed without making explicit memory copies - making these operations much faster.\n",
    "\n",
    "Rules for broadcasting are  the same as in numpy.\n",
    "[This](https://jakevdp.github.io/PythonDataScienceHandbook/02.05-computation-on-arrays-broadcasting.html) Is a pretty good reference if you want to dig deeper.\n",
    "\n",
    "There are three rules of broadcasting:\n",
    "   1. If the two arrays differ in their number of dimensions, the shape of the one with fewer dimensions is padded with ones on its leading (left) side.\n",
    "   1. If the shape of the two arrays does not match in any dimension, the array with shape equal to 1 in that dimension is stretched to match the other shape.\n",
    "   1.If in any dimension the sizes disagree and neither is equal to 1, an error is raised.  \n",
    "   Lets look at a few examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "WD2vOi7oFwVO"
   },
   "outputs": [],
   "source": [
    "a = torch.arange(3).to(device)\n",
    "\n",
    "b = torch.arange(3).to(device).view(-1,1).contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HDpt9fifIn5a",
    "outputId": "46121475-9115-4d11-f86e-612b7c039bb2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2], device='cuda:0')\n",
      "tensor([[0],\n",
      "        [1],\n",
      "        [2]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "xRLCgKL1Iykk"
   },
   "outputs": [],
   "source": [
    "c=a+b #Rule 1 was used first to make a (1,3) Rule 2 was used twice - to 'expand' a into (3,3) and b from (3,1) to (3,3) - now dimensions match and + can be performed element-wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k-Rs0F25I0tL",
    "outputId": "28156e60-c49e-4fd4-dac1-144d80923221"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2],\n",
      "        [1, 2, 3],\n",
      "        [2, 3, 4]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "vU8_DAQgI1w7"
   },
   "outputs": [],
   "source": [
    "d=c+a #here Rule 1 was used to expand a into (1,3) and then Rule 2 to stretch it to (3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QOq_RbeKJN5v",
    "outputId": "0be2661d-7961-4e53-d266-001324907ec1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 2, 4],\n",
      "        [1, 3, 5],\n",
      "        [2, 4, 6]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NoSLTbhtN9A0"
   },
   "source": [
    "Remember that the dimension is always 'prepended' to the list of dimensions. So this will not work because broadcast will try to turn `a` into (1,3,4) size tensor. Size 1 could be broadcast over the first dimension of `b`, but the second dimensions (3 and 4) are not matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "Qn5SgrS7OSkT",
    "outputId": "4396622e-4919-4c58-be14-076baba6dc58"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (4) must match the size of tensor b (5) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m a=torch.arange(\u001b[32m3\u001b[39m*\u001b[32m4\u001b[39m).to(device).view(\u001b[32m3\u001b[39m,\u001b[32m4\u001b[39m).contiguous()\n\u001b[32m      2\u001b[39m b=torch.arange(\u001b[32m3\u001b[39m*\u001b[32m4\u001b[39m*\u001b[32m5\u001b[39m).to(device).view(\u001b[32m3\u001b[39m,\u001b[32m4\u001b[39m,\u001b[32m5\u001b[39m).contiguous()\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43ma\u001b[49m\u001b[43m+\u001b[49m\u001b[43mb\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: The size of tensor a (4) must match the size of tensor b (5) at non-singleton dimension 2"
     ]
    }
   ],
   "source": [
    "a=torch.arange(3*4).to(device).view(3,4).contiguous()\n",
    "b=torch.arange(3*4*5).to(device).view(3,4,5).contiguous()\n",
    "a+b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zWjKcgTZOgzk"
   },
   "source": [
    "If the intention was to broadcast over the last dimension we need to add dimension to tensor a. A common method to do this is to `unsqueeze` it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "spUYMlAFPYxh",
    "outputId": "e6ef143c-a690-48e8-9c35-cb03cfa7a7ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11]], device='cuda:0')\n",
      "tensor([[[ 0],\n",
      "         [ 1],\n",
      "         [ 2],\n",
      "         [ 3]],\n",
      "\n",
      "        [[ 4],\n",
      "         [ 5],\n",
      "         [ 6],\n",
      "         [ 7]],\n",
      "\n",
      "        [[ 8],\n",
      "         [ 9],\n",
      "         [10],\n",
      "         [11]]], device='cuda:0')\n",
      "torch.Size([3, 4, 1])\n"
     ]
    }
   ],
   "source": [
    "print(a)\n",
    "a.unsqueeze_(-1)\n",
    "print(a)\n",
    "print(a.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wZJ9QY_NPglN"
   },
   "source": [
    "Now the broadcast will work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OUWZ_WPPP9cR",
    "outputId": "a5b1accf-84e1-4ad4-95a7-f49df1e89a38"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1,  2,  3,  4],\n",
       "         [ 6,  7,  8,  9, 10],\n",
       "         [12, 13, 14, 15, 16],\n",
       "         [18, 19, 20, 21, 22]],\n",
       "\n",
       "        [[24, 25, 26, 27, 28],\n",
       "         [30, 31, 32, 33, 34],\n",
       "         [36, 37, 38, 39, 40],\n",
       "         [42, 43, 44, 45, 46]],\n",
       "\n",
       "        [[48, 49, 50, 51, 52],\n",
       "         [54, 55, 56, 57, 58],\n",
       "         [60, 61, 62, 63, 64],\n",
       "         [66, 67, 68, 69, 70]]], device='cuda:0')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a+b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bJp7jVesP_B5"
   },
   "source": [
    "# Backpropagation\n",
    "The most common method to train neural networks employs backpropagation - i.e. evaluation of gradients of some function (usually the loss function) with respect to tensors that form the network parameters. Pytorch accomplishes this by building up a computational graph of all the operations as they are performed. Each tensor holds the information of what tensors were it's the sources and the operations used to make this tensor from the source tensors. Pytorch operations provide a functionality to compute the gradient of output with respect to input. Pytorch will than work backward from the root node i.e. the final tensor or 'backpropagate' to compute the gradient of the final tensor with respect to the input tensors or 'leaves' of the graph. This is really just chain rule - but thinking of the computation as a graph allows for automation of the whole process.  For this process to work the final value that we will ask pytorch to compute gradients for should be a scalar (It is possible to calculate gradients of non-scalar tensors - but we will not cover it here as it is not used very often)  \n",
    "\n",
    "\n",
    "First we'll install a tool that will help us visualize a simple graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If on colab only: uncomment (remove ###) and run the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wyqer0zPTDUw",
    "outputId": "6c427ef6-7e80-43f4-d329-99e74ec8181e"
   },
   "outputs": [],
   "source": [
    "### !pip install torchviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resume either on colab or TRIUMF machines/containers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "bHxg-LG4TEa0"
   },
   "outputs": [],
   "source": [
    "from torchviz import make_dot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J6OhRoS4XL8l"
   },
   "source": [
    "Now let's define two tensors and make a few computations arriving finally at a scalar tensor. Notice that we need to call `requires_grad_` on the leaf tensors. Normally tensors do not require that the gradients are computed with respect to them unless they are parameters of a neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aUpxYhK4TLak",
    "outputId": "1b560158-3857-430e-e34b-e7de18b19240"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: tensor([[0., 1.],\n",
      "        [2., 3.]], device='cuda:0', requires_grad=True)\n",
      "b: tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0', requires_grad=True)\n",
      "c: tensor([[ 0.,  2.],\n",
      "        [ 8., 18.]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "d: 28.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/_tensor.py:1128: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.\n",
      "Consider using tensor.detach() first. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/Scalar.cpp:22.)\n",
      "  return self.item().__format__(format_spec)\n"
     ]
    }
   ],
   "source": [
    "a=torch.arange(4,dtype=torch.float32).to(device).view(2,2).contiguous()\n",
    "a.requires_grad_()\n",
    "b=torch.zeros(2,2).to(device)\n",
    "b.requires_grad_()\n",
    "c=2*a**2+b\n",
    "d=c.sum()\n",
    "print('a: {}'.format(a))\n",
    "print('b: {}'.format(b))\n",
    "print('c: {}'.format(c))\n",
    "print('d: {}'.format(d))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PoGRyxAFXtW1"
   },
   "source": [
    "Here is our computational graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "id": "FZSoPh9aU7Aq",
    "outputId": "1e0625d5-b3ab-4797-e34c-0c8390ec624e"
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"222pt\" height=\"393pt\"\n",
       " viewBox=\"0.00 0.00 222.00 393.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 389)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-389 218,-389 218,4 -4,4\"/>\n",
       "<!-- 139758221055056 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>139758221055056</title>\n",
       "<polygon fill=\"#caff70\" stroke=\"black\" points=\"133.5,-31 79.5,-31 79.5,0 133.5,0 133.5,-31\"/>\n",
       "<text text-anchor=\"middle\" x=\"106.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\"> ()</text>\n",
       "</g>\n",
       "<!-- 139758224783920 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>139758224783920</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"151,-86 62,-86 62,-67 151,-67 151,-86\"/>\n",
       "<text text-anchor=\"middle\" x=\"106.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\">SumBackward0</text>\n",
       "</g>\n",
       "<!-- 139758224783920&#45;&gt;139758221055056 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>139758224783920&#45;&gt;139758221055056</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M106.5,-66.79C106.5,-60.07 106.5,-50.4 106.5,-41.34\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"110,-41.19 106.5,-31.19 103,-41.19 110,-41.19\"/>\n",
       "</g>\n",
       "<!-- 139758223898464 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>139758223898464</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"151,-141 62,-141 62,-122 151,-122 151,-141\"/>\n",
       "<text text-anchor=\"middle\" x=\"106.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">AddBackward0</text>\n",
       "</g>\n",
       "<!-- 139758223898464&#45;&gt;139758224783920 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>139758223898464&#45;&gt;139758224783920</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M106.5,-121.75C106.5,-114.8 106.5,-104.85 106.5,-96.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"110,-96.09 106.5,-86.09 103,-96.09 110,-96.09\"/>\n",
       "</g>\n",
       "<!-- 139758223898608 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>139758223898608</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"95,-196 6,-196 6,-177 95,-177 95,-196\"/>\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\">MulBackward0</text>\n",
       "</g>\n",
       "<!-- 139758223898608&#45;&gt;139758223898464 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>139758223898608&#45;&gt;139758223898464</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M59.5,-176.98C67.69,-169.23 80.01,-157.58 89.97,-148.14\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"92.48,-150.59 97.34,-141.17 87.67,-145.5 92.48,-150.59\"/>\n",
       "</g>\n",
       "<!-- 139758223898848 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>139758223898848</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"95,-257 6,-257 6,-238 95,-238 95,-257\"/>\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-245\" font-family=\"monospace\" font-size=\"10.00\">PowBackward0</text>\n",
       "</g>\n",
       "<!-- 139758223898848&#45;&gt;139758223898608 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>139758223898848&#45;&gt;139758223898608</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M50.5,-237.79C50.5,-229.6 50.5,-217.06 50.5,-206.55\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"54,-206.24 50.5,-196.24 47,-206.24 54,-206.24\"/>\n",
       "</g>\n",
       "<!-- 139758223898704 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>139758223898704</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"101,-318 0,-318 0,-299 101,-299 101,-318\"/>\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-306\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 139758223898704&#45;&gt;139758223898848 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>139758223898704&#45;&gt;139758223898848</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M50.5,-298.79C50.5,-290.6 50.5,-278.06 50.5,-267.55\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"54,-267.24 50.5,-257.24 47,-267.24 54,-267.24\"/>\n",
       "</g>\n",
       "<!-- 139758221053216 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>139758221053216</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"80,-385 21,-385 21,-354 80,-354 80,-385\"/>\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-361\" font-family=\"monospace\" font-size=\"10.00\"> (2, 2)</text>\n",
       "</g>\n",
       "<!-- 139758221053216&#45;&gt;139758223898704 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>139758221053216&#45;&gt;139758223898704</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M50.5,-353.92C50.5,-346.22 50.5,-336.69 50.5,-328.43\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"54,-328.25 50.5,-318.25 47,-328.25 54,-328.25\"/>\n",
       "</g>\n",
       "<!-- 139758223898656 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>139758223898656</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"214,-196 113,-196 113,-177 214,-177 214,-196\"/>\n",
       "<text text-anchor=\"middle\" x=\"163.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 139758223898656&#45;&gt;139758223898464 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>139758223898656&#45;&gt;139758223898464</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M154.34,-176.98C146,-169.23 133.47,-157.58 123.32,-148.14\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"125.53,-145.42 115.82,-141.17 120.76,-150.54 125.53,-145.42\"/>\n",
       "</g>\n",
       "<!-- 139757236143440 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>139757236143440</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"193,-263 134,-263 134,-232 193,-232 193,-263\"/>\n",
       "<text text-anchor=\"middle\" x=\"163.5\" y=\"-239\" font-family=\"monospace\" font-size=\"10.00\"> (2, 2)</text>\n",
       "</g>\n",
       "<!-- 139757236143440&#45;&gt;139758223898656 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>139757236143440&#45;&gt;139758223898656</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M163.5,-231.92C163.5,-224.22 163.5,-214.69 163.5,-206.43\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"167,-206.25 163.5,-196.25 160,-206.25 167,-206.25\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7f1bff6cbe00>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_dot(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "20BBByj7Xzvd"
   },
   "source": [
    "Now we can compute the gradients with respect to `a` and `b` evaluated at the values of `a` and `b` that entered the computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "rQvThv_8Wx8K"
   },
   "outputs": [],
   "source": [
    "d.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zwljsNwsYO8c",
    "outputId": "075ecc17-8a01-4118-8031-d7fda93c7acc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient with respect to a:\n",
      " tensor([[ 0.,  4.],\n",
      "        [ 8., 12.]], device='cuda:0')\n",
      "gradient with respect to b:\n",
      " tensor([[1., 1.],\n",
      "        [1., 1.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print('gradient with respect to a:\\n {}'.format(a.grad))\n",
    "print('gradient with respect to b:\\n {}'.format(b.grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "28K4hHRYgLkO"
   },
   "source": [
    "Make sure you can work out how these were computed and play around with modifying the inputs and the sequence of operations.  \n",
    "\n",
    "Congrats - you are in good shape to do some deep learning now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "znoIj87mnnf6"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
