{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zA1O5zIVfQwX"
      },
      "source": [
        "#Introduction\n",
        "In this notebook we will explore the idea of tensors, creating them, indexing and broadcasting. We will use pytorch - however if you know these concepts from numpy, you should be able to directly apply them in pytorch. We will also put them on a GPU and perform some simple calculations. Finally we will touch very briefly on gradient calculation - a concept essential in deep learning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuaA-RM1F-lh"
      },
      "source": [
        "#Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WMXG3KXtXnr"
      },
      "source": [
        "Before we begin change the Runtime to use a GPU: Click on 'Runtime' --> 'Change Runtime Type' -> from 'Hardware Accelerator' select GPU if it is not already selected."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U__sxNQxtxO2"
      },
      "source": [
        "Now lets check CUDA version and check pytorch installation, run the cells below in turn:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnIhaQYIt5m8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdb1fefa-bd6b-4ab2-f8e9-eaa5653b69f7"
      },
      "source": [
        "!nvcc --version"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2020 NVIDIA Corporation\n",
            "Built on Wed_Jul_22_19:09:09_PDT_2020\n",
            "Cuda compilation tools, release 11.0, V11.0.221\n",
            "Build cuda_11.0_bu.TC445_37.28845127_0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udtlf7qht7bS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a17cc2d-0d1f-407e-8229-94d256d41424"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Jun  2 06:22:00 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   47C    P8    29W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMtjp8-380ye"
      },
      "source": [
        "You should see that nvcc - cuda compiler has version 10.0 or later and that one GPU is present in the table above, for instance a Tesla K80. Now let's check if pytorch is already installed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgdbq7oX9EjV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a601e7ad-b56d-4e45-8304-b0651c7e648b"
      },
      "source": [
        "import torch\n",
        "if torch is not None:\n",
        "  print(\"OK we have pytorch installed\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OK we have pytorch installed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4GB6I9EgI2T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1b79a4dd-bf32-4b51-cd28-cd0416330eb1"
      },
      "source": [
        "torch.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.8.1+cu101'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kRbQ9tJ9IEn"
      },
      "source": [
        "If the cell above failed and did not print 'OK we have pytorch installed' there is a problem --> Talk to Wojtek"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P37Z4VS_GGi7"
      },
      "source": [
        "#Tensors\n",
        "In this section we will play a bit with pytorch tensors. If you used numpy before this will be very familiar."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1fTMAUz0d4f"
      },
      "source": [
        "import torch\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7ZQCHBeLPTA"
      },
      "source": [
        "## Declaring Tensors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0FojOEl-WH4"
      },
      "source": [
        "We can declare tensors from lists, numpy arrays, other tensors, or by calling pytorch functions which initialize tensors to certain values (e.g. random, zeros, fill values etc)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2qYXIzs1aZT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "231cd07c-0259-481a-d308-50e93ecc2e33"
      },
      "source": [
        "a = torch.tensor([0, 1, 2])\n",
        "a_float=torch.tensor([0.0,1.0,2.0])\n",
        "b_np=np.random.randn(3,4,5)\n",
        "b=torch.tensor(b_np)\n",
        "c=torch.zeros(3,4,5)\n",
        "d=torch.randn(3,4,5)\n",
        "print(\"Declared tensors:\")\n",
        "print(\"a: {}\".format(a))\n",
        "print(\"a_float: {}\".format(a_float))\n",
        "print(\"b: {}\".format(b))\n",
        "print(\"c: {}\".format(c))\n",
        "print(\"d: {}\".format(d))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Declared tensors:\n",
            "a: tensor([0, 1, 2])\n",
            "a_float: tensor([0., 1., 2.])\n",
            "b: tensor([[[ 0.3031, -0.9410,  0.8257,  1.7529,  0.0230],\n",
            "         [-1.6616, -2.4221, -0.9331, -0.8336,  0.8142],\n",
            "         [ 0.4914,  0.5698,  0.0335,  0.0852, -0.8081],\n",
            "         [ 0.5341,  0.5830, -0.0974, -1.5876,  0.1284]],\n",
            "\n",
            "        [[ 1.4968,  0.3382,  0.7454, -1.1311,  1.8682],\n",
            "         [ 1.4613,  1.4968, -0.9776,  1.3471,  0.7633],\n",
            "         [ 1.0132, -0.5484,  0.3356, -0.5152,  0.9161],\n",
            "         [ 2.0261, -0.1662,  0.7628,  0.8990, -0.2767]],\n",
            "\n",
            "        [[ 0.4614, -0.7658,  0.7489,  0.4006, -0.3454],\n",
            "         [ 0.4659, -0.5025, -2.2927,  0.1293, -0.4214],\n",
            "         [-0.0929,  1.0068,  1.2346, -1.3125,  0.1412],\n",
            "         [ 0.2770, -1.1017, -0.8735, -1.3373,  0.9099]]], dtype=torch.float64)\n",
            "c: tensor([[[0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0.]]])\n",
            "d: tensor([[[ 1.7855, -1.2665, -0.3650,  1.4456, -0.3209],\n",
            "         [ 0.3474,  0.2213, -0.5474,  0.0227,  0.2400],\n",
            "         [-0.7765, -1.6931,  0.2010,  0.6905,  1.4738],\n",
            "         [-0.4600, -1.8857,  2.4509, -1.1097, -0.3352]],\n",
            "\n",
            "        [[ 0.0301,  0.4167, -0.6072, -0.4291, -0.3082],\n",
            "         [ 1.0533, -1.0894,  1.0459,  0.3627, -1.5682],\n",
            "         [ 0.1385, -2.4817, -1.4930,  1.5746, -1.0651],\n",
            "         [ 0.5203, -0.3325, -1.8414, -1.1974, -0.1034]],\n",
            "\n",
            "        [[ 0.1694,  0.1755, -0.4775,  1.6110,  0.1575],\n",
            "         [-0.5813,  1.2096,  0.7305, -0.4683, -0.5576],\n",
            "         [-0.6264,  0.6378, -0.8931,  1.4489, -0.1900],\n",
            "         [-1.6131, -0.8555,  0.0778,  0.6956,  0.7473]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDNuaXMY3OVC"
      },
      "source": [
        "## Indexing tensors\n",
        "indexing works almost identically to numpy indexing including slicing and fancy indexing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQWt3JpB3Ef4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c1d3db0-4706-47e7-e254-968a84213c9d"
      },
      "source": [
        "print(d[0,0,0])\n",
        "print(d[:,1::2,:-1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(1.7855)\n",
            "tensor([[[ 0.3474,  0.2213, -0.5474,  0.0227],\n",
            "         [-0.4600, -1.8857,  2.4509, -1.1097]],\n",
            "\n",
            "        [[ 1.0533, -1.0894,  1.0459,  0.3627],\n",
            "         [ 0.5203, -0.3325, -1.8414, -1.1974]],\n",
            "\n",
            "        [[-0.5813,  1.2096,  0.7305, -0.4683],\n",
            "         [-1.6131, -0.8555,  0.0778,  0.6956]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRxSauKiEFWy"
      },
      "source": [
        "You may even use tensors to index tensors,"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwQyIjK_EMFo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f986b680-b0e9-44fc-8d08-3294960685d9"
      },
      "source": [
        "d[a,a,a]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1.7855, -1.0894, -0.8931])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gr4cGXeKEvwC"
      },
      "source": [
        "But - if you do that the tensor you are using to index should be integer type (or long integer). The cell below illustrates this - it will raise `IndexError`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YP9jFPvFEg4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "outputId": "722069ac-40e2-4048-bb1c-7bc9a1640e94"
      },
      "source": [
        "d[a_float,a_float,a_float]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-d09f6e5f32df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma_float\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma_float\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma_float\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m: tensors used as indices must be long, byte or bool tensors"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pW9WwioZ3aWg"
      },
      "source": [
        "There is one common pitfall - when you index a particular position in a tensor - you get a '0 dimensional' tensor:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCdZne_8Eu7D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22aa34a2-2784-43cb-d8ea-c1bb7fdd7ae7"
      },
      "source": [
        "d[1,1,1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-1.0894)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZznLvFkKwgh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06431437-9ba0-4bb8-a1d7-0c8d83c13b16"
      },
      "source": [
        "d[1,1,1].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5DPoaYwK2H4"
      },
      "source": [
        "To get the actual number we need to use `item()` method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ua-IwOzw3FcJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9434d2b4-fc57-4f65-b64b-00ccb1107b9e"
      },
      "source": [
        "d[1,1,1].item()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-1.0894254446029663"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AobtyN1n3nZK"
      },
      "source": [
        "Pay attention to the datatype of the tensor. Generally we want float32 type tensors for data in deep learning and long integer tensors for labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXSAGQgV3KI4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20668066-4020-4282-9714-6043d4c4250b"
      },
      "source": [
        "print(a.dtype)\n",
        "print(b.dtype)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.int64\n",
            "torch.float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MiuIqFOzAyJY"
      },
      "source": [
        "##Using GPUs\n",
        "We'll now send some data to the GPU and perform some example calculations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJdKQtwfBEp7"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    d=d.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJADPCyBBLNU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18dc0443-210d-4b2b-a976-232acee3a223"
      },
      "source": [
        "print(d)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[ 1.7855, -1.2665, -0.3650,  1.4456, -0.3209],\n",
            "         [ 0.3474,  0.2213, -0.5474,  0.0227,  0.2400],\n",
            "         [-0.7765, -1.6931,  0.2010,  0.6905,  1.4738],\n",
            "         [-0.4600, -1.8857,  2.4509, -1.1097, -0.3352]],\n",
            "\n",
            "        [[ 0.0301,  0.4167, -0.6072, -0.4291, -0.3082],\n",
            "         [ 1.0533, -1.0894,  1.0459,  0.3627, -1.5682],\n",
            "         [ 0.1385, -2.4817, -1.4930,  1.5746, -1.0651],\n",
            "         [ 0.5203, -0.3325, -1.8414, -1.1974, -0.1034]],\n",
            "\n",
            "        [[ 0.1694,  0.1755, -0.4775,  1.6110,  0.1575],\n",
            "         [-0.5813,  1.2096,  0.7305, -0.4683, -0.5576],\n",
            "         [-0.6264,  0.6378, -0.8931,  1.4489, -0.1900],\n",
            "         [-1.6131, -0.8555,  0.0778,  0.6956,  0.7473]]], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2uWQ1VqmMsSX"
      },
      "source": [
        "We can now perform some calculations which will be performed by the GPU. For instance element-wise addition:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QpQPBc_NFoa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78ac2e9a-8ea8-415a-8b51-7364e5361c0a"
      },
      "source": [
        "e=d+d\n",
        "print(e)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[ 3.5709, -2.5330, -0.7300,  2.8912, -0.6419],\n",
            "         [ 0.6947,  0.4426, -1.0948,  0.0453,  0.4799],\n",
            "         [-1.5531, -3.3861,  0.4020,  1.3809,  2.9476],\n",
            "         [-0.9200, -3.7715,  4.9017, -2.2194, -0.6705]],\n",
            "\n",
            "        [[ 0.0601,  0.8335, -1.2143, -0.8583, -0.6164],\n",
            "         [ 2.1066, -2.1789,  2.0918,  0.7253, -3.1363],\n",
            "         [ 0.2770, -4.9635, -2.9860,  3.1491, -2.1303],\n",
            "         [ 1.0405, -0.6650, -3.6828, -2.3948, -0.2067]],\n",
            "\n",
            "        [[ 0.3389,  0.3510, -0.9551,  3.2220,  0.3150],\n",
            "         [-1.1626,  2.4193,  1.4610, -0.9366, -1.1151],\n",
            "         [-1.2528,  1.2755, -1.7863,  2.8978, -0.3801],\n",
            "         [-3.2263, -1.7110,  0.1556,  1.3911,  1.4946]]], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFMKEgJ9NLBg"
      },
      "source": [
        "As you can see above the output stays on GPU. You can't perform operations on tensors residing on different devices, the next cell will fail."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTBwNNrqlUo3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "outputId": "ed82fb55-332f-4643-b8e1-8cd8b9ee9801"
      },
      "source": [
        "c+d"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-ad687b5fa348>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mc\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVLYOLgloaiQ"
      },
      "source": [
        "##Tensor operations, shape and reshaping\n",
        "In the cells above we performed a element-wise addition using `+` -  but this is overloaded `add()` function. You can take a look at the available operations [here](https://pytorch.org/docs/stable/tensors.html#torch.Tensor). Most of the available operations have an in-place version - the convention is that the name of that operation ends with `_`. The output of these will be assigned to the tensor the operation is called on. This can save some memory but can be a bit [tricky](https://pytorch.org/docs/stable/notes/autograd.html#in-place-operations-with-autograd) if we use the tensor to calculate gradients. The cell below illustrates how to use both styles."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ud_VOtvRqstV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fac80d27-3217-4d51-c68d-903d43102a21"
      },
      "source": [
        "dcpy=d.clone()\n",
        "d_plus_d=d.add(d)\n",
        "\n",
        "dcpy.add_(dcpy)\n",
        "print(\"d_plus_d: {}\\n\\ndcpy: {}\".format(d_plus_d,dcpy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "d_plus_d: tensor([[[ 3.5709, -2.5330, -0.7300,  2.8912, -0.6419],\n",
            "         [ 0.6947,  0.4426, -1.0948,  0.0453,  0.4799],\n",
            "         [-1.5531, -3.3861,  0.4020,  1.3809,  2.9476],\n",
            "         [-0.9200, -3.7715,  4.9017, -2.2194, -0.6705]],\n",
            "\n",
            "        [[ 0.0601,  0.8335, -1.2143, -0.8583, -0.6164],\n",
            "         [ 2.1066, -2.1789,  2.0918,  0.7253, -3.1363],\n",
            "         [ 0.2770, -4.9635, -2.9860,  3.1491, -2.1303],\n",
            "         [ 1.0405, -0.6650, -3.6828, -2.3948, -0.2067]],\n",
            "\n",
            "        [[ 0.3389,  0.3510, -0.9551,  3.2220,  0.3150],\n",
            "         [-1.1626,  2.4193,  1.4610, -0.9366, -1.1151],\n",
            "         [-1.2528,  1.2755, -1.7863,  2.8978, -0.3801],\n",
            "         [-3.2263, -1.7110,  0.1556,  1.3911,  1.4946]]], device='cuda:0')\n",
            "\n",
            "dcpy: tensor([[[ 3.5709, -2.5330, -0.7300,  2.8912, -0.6419],\n",
            "         [ 0.6947,  0.4426, -1.0948,  0.0453,  0.4799],\n",
            "         [-1.5531, -3.3861,  0.4020,  1.3809,  2.9476],\n",
            "         [-0.9200, -3.7715,  4.9017, -2.2194, -0.6705]],\n",
            "\n",
            "        [[ 0.0601,  0.8335, -1.2143, -0.8583, -0.6164],\n",
            "         [ 2.1066, -2.1789,  2.0918,  0.7253, -3.1363],\n",
            "         [ 0.2770, -4.9635, -2.9860,  3.1491, -2.1303],\n",
            "         [ 1.0405, -0.6650, -3.6828, -2.3948, -0.2067]],\n",
            "\n",
            "        [[ 0.3389,  0.3510, -0.9551,  3.2220,  0.3150],\n",
            "         [-1.1626,  2.4193,  1.4610, -0.9366, -1.1151],\n",
            "         [-1.2528,  1.2755, -1.7863,  2.8978, -0.3801],\n",
            "         [-3.2263, -1.7110,  0.1556,  1.3911,  1.4946]]], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJTX1jPfKWER"
      },
      "source": [
        "For future reference we will clone tensor d"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isaE7O95Ka75"
      },
      "source": [
        "dcpy=d.clone()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8USAvewTuQ83"
      },
      "source": [
        "Often we will need to change shape of the tensor. We have two options to find a shape of a tensor `size()` and `shape`- these are completely equivalent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJjVRbwokc8q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7912d27-d08b-40a1-86ab-2617fbe9784f"
      },
      "source": [
        "print(d.shape)\n",
        "print(d.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 4, 5])\n",
            "torch.Size([3, 4, 5])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f89A2VAIk8HI"
      },
      "source": [
        "To change tensor shapes we have two options: `view` and `reshape`.  `view` as the name implies gives you a pointer to the same memory location but with adjusted 'strides' so that the shape is as you specify i.e. a new 'view' of the same data. On the other hand `reshape` will give you a view of a tensor, if it is possible (i.e. if the tensor's memory is contiguous), or a copy if it is not. As a rule of thumb avoid using `reshape`. If a copy of a tensor is needed with explicit new (contiguous) memory allocation use `clone`. The cells below give some examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOoX5mdfwuX5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c0cb933-c504-4f44-ef7a-3eaaf42ac0eb"
      },
      "source": [
        "'''\n",
        "lets unroll the first dimension of d and rearrange the last two dimensions.\n",
        "Giving -1 as a parameter, just like in numpy reshape,\n",
        "will figure out what the dimension ought to be\n",
        "'''\n",
        "d_unroll_reshape=d.view(5,-1)\n",
        "print(d)\n",
        "print(d_unroll_reshape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[ 1.7855, -1.2665, -0.3650,  1.4456, -0.3209],\n",
            "         [ 0.3474,  0.2213, -0.5474,  0.0227,  0.2400],\n",
            "         [-0.7765, -1.6931,  0.2010,  0.6905,  1.4738],\n",
            "         [-0.4600, -1.8857,  2.4509, -1.1097, -0.3352]],\n",
            "\n",
            "        [[ 0.0301,  0.4167, -0.6072, -0.4291, -0.3082],\n",
            "         [ 1.0533, -1.0894,  1.0459,  0.3627, -1.5682],\n",
            "         [ 0.1385, -2.4817, -1.4930,  1.5746, -1.0651],\n",
            "         [ 0.5203, -0.3325, -1.8414, -1.1974, -0.1034]],\n",
            "\n",
            "        [[ 0.1694,  0.1755, -0.4775,  1.6110,  0.1575],\n",
            "         [-0.5813,  1.2096,  0.7305, -0.4683, -0.5576],\n",
            "         [-0.6264,  0.6378, -0.8931,  1.4489, -0.1900],\n",
            "         [-1.6131, -0.8555,  0.0778,  0.6956,  0.7473]]], device='cuda:0')\n",
            "tensor([[ 1.7855, -1.2665, -0.3650,  1.4456, -0.3209,  0.3474,  0.2213, -0.5474,\n",
            "          0.0227,  0.2400, -0.7765, -1.6931],\n",
            "        [ 0.2010,  0.6905,  1.4738, -0.4600, -1.8857,  2.4509, -1.1097, -0.3352,\n",
            "          0.0301,  0.4167, -0.6072, -0.4291],\n",
            "        [-0.3082,  1.0533, -1.0894,  1.0459,  0.3627, -1.5682,  0.1385, -2.4817,\n",
            "         -1.4930,  1.5746, -1.0651,  0.5203],\n",
            "        [-0.3325, -1.8414, -1.1974, -0.1034,  0.1694,  0.1755, -0.4775,  1.6110,\n",
            "          0.1575, -0.5813,  1.2096,  0.7305],\n",
            "        [-0.4683, -0.5576, -0.6264,  0.6378, -0.8931,  1.4489, -0.1900, -1.6131,\n",
            "         -0.8555,  0.0778,  0.6956,  0.7473]], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVBg5bDDzp8B"
      },
      "source": [
        "As you can see pytorch figured out that the last dimension should be 12. Again beware - the tensors `d` and `d_unroll_reshape` share data. Let's modify one element in `d` and watch it change in `d_unroll_reshape`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgdmtjdD0ulD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "503c5553-1c11-4fe7-fea4-2ab7ce0318b2"
      },
      "source": [
        "d[0,2,1]=42.0\n",
        "print(d_unroll_reshape[0,-1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(42., device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEgFNOKo1LrX"
      },
      "source": [
        "Use `clone` if you want brand new memory for the tensor. You can of course stack the operations -e.g. view and then clone. Now changing one will not affect the other."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hh3hZPdt4k_i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30a3c6cd-50a3-4518-a412-d34dd208510d"
      },
      "source": [
        "d_unroll_reshape_cloned=d.view(5,-1).clone()\n",
        "d_unroll_reshape_cloned[0,-1]=1984.0\n",
        "print(d[0,2,1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(42., device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCxxorwfyqDI"
      },
      "source": [
        "Some operations will make the tensor non-contiguous. For instance the transpose operation. The data in memory will not be touched, just the strides affected. This means that it is impossible to get a different view of the tensor. Transposing the last two dimensions:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xylwsQqVuAuw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2488d1a-b9c4-4992-a178-88c990255a1f"
      },
      "source": [
        "d.transpose_(1,2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 1.7855e+00,  3.4737e-01, -7.7654e-01, -4.5999e-01],\n",
              "         [-1.2665e+00,  2.2131e-01,  4.2000e+01, -1.8857e+00],\n",
              "         [-3.6501e-01, -5.4738e-01,  2.0100e-01,  2.4509e+00],\n",
              "         [ 1.4456e+00,  2.2662e-02,  6.9046e-01, -1.1097e+00],\n",
              "         [-3.2093e-01,  2.3996e-01,  1.4738e+00, -3.3523e-01]],\n",
              "\n",
              "        [[ 3.0069e-02,  1.0533e+00,  1.3850e-01,  5.2026e-01],\n",
              "         [ 4.1673e-01, -1.0894e+00, -2.4817e+00, -3.3251e-01],\n",
              "         [-6.0717e-01,  1.0459e+00, -1.4930e+00, -1.8414e+00],\n",
              "         [-4.2913e-01,  3.6265e-01,  1.5746e+00, -1.1974e+00],\n",
              "         [-3.0819e-01, -1.5682e+00, -1.0651e+00, -1.0336e-01]],\n",
              "\n",
              "        [[ 1.6945e-01, -5.8128e-01, -6.2638e-01, -1.6131e+00],\n",
              "         [ 1.7549e-01,  1.2096e+00,  6.3776e-01, -8.5548e-01],\n",
              "         [-4.7754e-01,  7.3048e-01, -8.9313e-01,  7.7793e-02],\n",
              "         [ 1.6110e+00, -4.6828e-01,  1.4489e+00,  6.9555e-01],\n",
              "         [ 1.5749e-01, -5.5755e-01, -1.9005e-01,  7.4730e-01]]],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hoLsyl-DdMj"
      },
      "source": [
        "After the transpose the entries in a single 'row' in the above tensor are not 'neighbours' in memory - the two numbers in the column are - so we can not reshape the tensor easliy;\n",
        "This will fail:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNPMmFBoDNEd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "outputId": "e91d4c5b-c1ae-4c49-f02c-cb3f59ca3e5d"
      },
      "source": [
        "d_back_to_original_shape=d.view(3,4,5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-7d0e5b60c126>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0md_back_to_original_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tILqp6BE0a3"
      },
      "source": [
        "We need to copy the tensor to contiguous memory space and then we can reshape it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BR1nbD-NDW6i"
      },
      "source": [
        "d_back_to_original_shape=d.contiguous().view(3,4,5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YclGpIDTH-Lj"
      },
      "source": [
        "Back close to the start we made a copy of d naming it `dcpy`. Lets print it now alongside d. Notice the difference in the tensors after all these reshaping operations? Do you understand what happened?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRaE4H4YFu7X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17e70c6d-3d3c-477c-8304-fa0a8bfa747e"
      },
      "source": [
        "print(\"dcpy: {}\".format(dcpy))\n",
        "print(\"d_back_to_original_shape: {}\".format(d_back_to_original_shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dcpy: tensor([[[ 1.7855, -1.2665, -0.3650,  1.4456, -0.3209],\n",
            "         [ 0.3474,  0.2213, -0.5474,  0.0227,  0.2400],\n",
            "         [-0.7765, -1.6931,  0.2010,  0.6905,  1.4738],\n",
            "         [-0.4600, -1.8857,  2.4509, -1.1097, -0.3352]],\n",
            "\n",
            "        [[ 0.0301,  0.4167, -0.6072, -0.4291, -0.3082],\n",
            "         [ 1.0533, -1.0894,  1.0459,  0.3627, -1.5682],\n",
            "         [ 0.1385, -2.4817, -1.4930,  1.5746, -1.0651],\n",
            "         [ 0.5203, -0.3325, -1.8414, -1.1974, -0.1034]],\n",
            "\n",
            "        [[ 0.1694,  0.1755, -0.4775,  1.6110,  0.1575],\n",
            "         [-0.5813,  1.2096,  0.7305, -0.4683, -0.5576],\n",
            "         [-0.6264,  0.6378, -0.8931,  1.4489, -0.1900],\n",
            "         [-1.6131, -0.8555,  0.0778,  0.6956,  0.7473]]], device='cuda:0')\n",
            "d_back_to_original_shape: tensor([[[ 1.7855e+00,  3.4737e-01, -7.7654e-01, -4.5999e-01, -1.2665e+00],\n",
            "         [ 2.2131e-01,  4.2000e+01, -1.8857e+00, -3.6501e-01, -5.4738e-01],\n",
            "         [ 2.0100e-01,  2.4509e+00,  1.4456e+00,  2.2662e-02,  6.9046e-01],\n",
            "         [-1.1097e+00, -3.2093e-01,  2.3996e-01,  1.4738e+00, -3.3523e-01]],\n",
            "\n",
            "        [[ 3.0069e-02,  1.0533e+00,  1.3850e-01,  5.2026e-01,  4.1673e-01],\n",
            "         [-1.0894e+00, -2.4817e+00, -3.3251e-01, -6.0717e-01,  1.0459e+00],\n",
            "         [-1.4930e+00, -1.8414e+00, -4.2913e-01,  3.6265e-01,  1.5746e+00],\n",
            "         [-1.1974e+00, -3.0819e-01, -1.5682e+00, -1.0651e+00, -1.0336e-01]],\n",
            "\n",
            "        [[ 1.6945e-01, -5.8128e-01, -6.2638e-01, -1.6131e+00,  1.7549e-01],\n",
            "         [ 1.2096e+00,  6.3776e-01, -8.5548e-01, -4.7754e-01,  7.3048e-01],\n",
            "         [-8.9313e-01,  7.7793e-02,  1.6110e+00, -4.6828e-01,  1.4489e+00],\n",
            "         [ 6.9555e-01,  1.5749e-01, -5.5755e-01, -1.9005e-01,  7.4730e-01]]],\n",
            "       device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYtt93NiG3Yn"
      },
      "source": [
        "#Broadcasting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrtNDEzZG66e"
      },
      "source": [
        "A very useful feature of numpy and torch tensors is the ability to broadcast. It is a mechanism where operations on pairs of tensors of different dimensionalities can be performed without making explicit memory copies - making these operations much faster.\n",
        "\n",
        "Rules for broadcasting are  the same as in numpy.\n",
        "[This](https://jakevdp.github.io/PythonDataScienceHandbook/02.05-computation-on-arrays-broadcasting.html) Is a pretty good reference if you want to dig deeper.\n",
        "\n",
        "There are three rules of broadcasting:\n",
        "   1. If the two arrays differ in their number of dimensions, the shape of the one with fewer dimensions is padded with ones on its leading (left) side.\n",
        "   1. If the shape of the two arrays does not match in any dimension, the array with shape equal to 1 in that dimension is stretched to match the other shape.\n",
        "   1.If in any dimension the sizes disagree and neither is equal to 1, an error is raised.  \n",
        "   Lets look at a few examples:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WD2vOi7oFwVO"
      },
      "source": [
        "a = torch.arange(3).to(device)\n",
        "\n",
        "b = torch.arange(3).to(device).view(-1,1).contiguous()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDpt9fifIn5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46121475-9115-4d11-f86e-612b7c039bb2"
      },
      "source": [
        "print(a)\n",
        "print(b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0, 1, 2], device='cuda:0')\n",
            "tensor([[0],\n",
            "        [1],\n",
            "        [2]], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRLCgKL1Iykk"
      },
      "source": [
        "c=a+b #Rule 1 was used first to make a (1,3) Rule 2 was used twice - to 'expand' a into (3,3) and b from (3,1) to (3,3) - now dimensions match and + can be performed element-wise"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-Rs0F25I0tL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28156e60-c49e-4fd4-dac1-144d80923221"
      },
      "source": [
        "print(c)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0, 1, 2],\n",
            "        [1, 2, 3],\n",
            "        [2, 3, 4]], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vU8_DAQgI1w7"
      },
      "source": [
        "d=c+a #here Rule 1 was used to expand a into (1,3) and then Rule 2 to stretch it to (3,3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOq_RbeKJN5v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0be2661d-7961-4e53-d266-001324907ec1"
      },
      "source": [
        "print(d)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0, 2, 4],\n",
            "        [1, 3, 5],\n",
            "        [2, 4, 6]], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NoSLTbhtN9A0"
      },
      "source": [
        "Remember that the dimension is always 'prepended' to the list of dimensions. So this will not work because broadcast will try to turn `a` into (1,3,4) size tensor. Size 1 could be broadcast over the first dimension of `b`, but the second dimensions (3 and 4) are not matching."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qn5SgrS7OSkT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "4396622e-4919-4c58-be14-076baba6dc58"
      },
      "source": [
        "a=torch.arange(3*4).to(device).view(3,4).contiguous()\n",
        "b=torch.arange(3*4*5).to(device).view(3,4,5).contiguous()\n",
        "a+b"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-45305ba7d0c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (4) must match the size of tensor b (5) at non-singleton dimension 2"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWjKcgTZOgzk"
      },
      "source": [
        "If the intention was to broadcast over the last dimension we need to add dimension to tensor a. A common method to do this is to `unsqueeze` it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spUYMlAFPYxh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6ef143c-a690-48e8-9c35-cb03cfa7a7ae"
      },
      "source": [
        "print(a)\n",
        "a.unsqueeze_(-1)\n",
        "print(a)\n",
        "print(a.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0,  1,  2,  3],\n",
            "        [ 4,  5,  6,  7],\n",
            "        [ 8,  9, 10, 11]], device='cuda:0')\n",
            "tensor([[[ 0],\n",
            "         [ 1],\n",
            "         [ 2],\n",
            "         [ 3]],\n",
            "\n",
            "        [[ 4],\n",
            "         [ 5],\n",
            "         [ 6],\n",
            "         [ 7]],\n",
            "\n",
            "        [[ 8],\n",
            "         [ 9],\n",
            "         [10],\n",
            "         [11]]], device='cuda:0')\n",
            "torch.Size([3, 4, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZJ9QY_NPglN"
      },
      "source": [
        "Now the broadcast will work:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUWZ_WPPP9cR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5b1accf-84e1-4ad4-95a7-f49df1e89a38"
      },
      "source": [
        "a+b"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0,  1,  2,  3,  4],\n",
              "         [ 6,  7,  8,  9, 10],\n",
              "         [12, 13, 14, 15, 16],\n",
              "         [18, 19, 20, 21, 22]],\n",
              "\n",
              "        [[24, 25, 26, 27, 28],\n",
              "         [30, 31, 32, 33, 34],\n",
              "         [36, 37, 38, 39, 40],\n",
              "         [42, 43, 44, 45, 46]],\n",
              "\n",
              "        [[48, 49, 50, 51, 52],\n",
              "         [54, 55, 56, 57, 58],\n",
              "         [60, 61, 62, 63, 64],\n",
              "         [66, 67, 68, 69, 70]]], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJp7jVesP_B5"
      },
      "source": [
        "#Backpropagation\n",
        "The most common method to train neural networks employs backpropagation - i.e. evaluation of gradients of some function (usually the loss function) with respect to tensors that form the network parameters. Pytorch accomplishes this by building up a computational graph of all the operations as they are performed. Each tensor holds the information of what tensors were it's the sources and the operations used to make this tensor from the source tensors. Pytorch operations provide a functionality to compute the gradient of output with respect to input. Pytorch will than work backward from the root node i.e. the final tensor or 'backpropagate' to compute the gradient of the final tensor with respect to the input tensors or 'leaves' of the graph. This is really just chain rule - but thinking of the computation as a graph allows for automation of the whole process.  For this process to work the final value that we will ask pytorch to compute gradients for should be a scalar (It is possible to calculate gradients of non-scalar tensors - but we will not cover it here as it is not used very often)  \n",
        "\n",
        "\n",
        "First we'll install a tool that will help us visualize a simple graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wyqer0zPTDUw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c427ef6-7e80-43f4-d329-99e74ec8181e"
      },
      "source": [
        "!pip install torchviz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchviz\n",
            "  Downloading https://files.pythonhosted.org/packages/79/e7/643808913211d6c1fc96a3a4333bf4c9276858fab00bcafaf98ea58a97be/torchviz-0.0.2.tar.gz\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchviz) (1.8.1+cu101)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from torchviz) (0.10.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch->torchviz) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchviz) (3.7.4.3)\n",
            "Building wheels for collected packages: torchviz\n",
            "  Building wheel for torchviz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchviz: filename=torchviz-0.0.2-cp37-none-any.whl size=4152 sha256=11b2da80f5900dbf4534690566176be068076acc3c94447747cb8f4b01cb3648\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/26/58/026ffd533dbe8b3972eb423da9c7949beca68d1c98ed9e8624\n",
            "Successfully built torchviz\n",
            "Installing collected packages: torchviz\n",
            "Successfully installed torchviz-0.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHxg-LG4TEa0"
      },
      "source": [
        "from torchviz import make_dot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6OhRoS4XL8l"
      },
      "source": [
        "Now let's define two tensors and make a few computations arriving finally at a scalar tensor. Notice that we need to call `requires_grad_` on the leaf tensors. Normally tensors do not require that the gradients are computed with respect to them unless they are parameters of a neural network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUpxYhK4TLak",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b560158-3857-430e-e34b-e7de18b19240"
      },
      "source": [
        "a=torch.arange(4,dtype=torch.float32).to(device).view(2,2).contiguous()\n",
        "a.requires_grad_()\n",
        "b=torch.zeros(2,2).to(device)\n",
        "b.requires_grad_()\n",
        "c=2*a**2+b\n",
        "d=c.sum()\n",
        "print('a: {}'.format(a))\n",
        "print('b: {}'.format(b))\n",
        "print('c: {}'.format(c))\n",
        "print('d: {}'.format(d))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a: tensor([[0., 1.],\n",
            "        [2., 3.]], device='cuda:0', requires_grad=True)\n",
            "b: tensor([[0., 0.],\n",
            "        [0., 0.]], device='cuda:0', requires_grad=True)\n",
            "c: tensor([[ 0.,  2.],\n",
            "        [ 8., 18.]], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "d: 28.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PoGRyxAFXtW1"
      },
      "source": [
        "Here is our computational graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZSoPh9aU7Aq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "1e0625d5-b3ab-4797-e34c-0c8390ec624e"
      },
      "source": [
        "make_dot(d)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.dot.Digraph at 0x7f058921c590>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"222pt\" height=\"393pt\"\n viewBox=\"0.00 0.00 222.00 393.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 389)\">\n<title>%3</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-389 218,-389 218,4 -4,4\"/>\n<!-- 139661776620432 -->\n<g id=\"node1\" class=\"node\">\n<title>139661776620432</title>\n<polygon fill=\"#caff70\" stroke=\"#000000\" points=\"133.5,-31 79.5,-31 79.5,0 133.5,0 133.5,-31\"/>\n<text text-anchor=\"middle\" x=\"106.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> ()</text>\n</g>\n<!-- 139661752256400 -->\n<g id=\"node2\" class=\"node\">\n<title>139661752256400</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"151,-86 62,-86 62,-67 151,-67 151,-86\"/>\n<text text-anchor=\"middle\" x=\"106.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">SumBackward0</text>\n</g>\n<!-- 139661752256400&#45;&gt;139661776620432 -->\n<g id=\"edge8\" class=\"edge\">\n<title>139661752256400&#45;&gt;139661776620432</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M106.5,-66.9688C106.5,-60.1289 106.5,-50.5621 106.5,-41.5298\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"110.0001,-41.3678 106.5,-31.3678 103.0001,-41.3678 110.0001,-41.3678\"/>\n</g>\n<!-- 139661752256464 -->\n<g id=\"node3\" class=\"node\">\n<title>139661752256464</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"151,-141 62,-141 62,-122 151,-122 151,-141\"/>\n<text text-anchor=\"middle\" x=\"106.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AddBackward0</text>\n</g>\n<!-- 139661752256464&#45;&gt;139661752256400 -->\n<g id=\"edge1\" class=\"edge\">\n<title>139661752256464&#45;&gt;139661752256400</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M106.5,-121.9197C106.5,-114.9083 106.5,-105.1442 106.5,-96.4652\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"110.0001,-96.3408 106.5,-86.3408 103.0001,-96.3409 110.0001,-96.3408\"/>\n</g>\n<!-- 139661752256272 -->\n<g id=\"node4\" class=\"node\">\n<title>139661752256272</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"95,-196 6,-196 6,-177 95,-177 95,-196\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">MulBackward0</text>\n</g>\n<!-- 139661752256272&#45;&gt;139661752256464 -->\n<g id=\"edge2\" class=\"edge\">\n<title>139661752256272&#45;&gt;139661752256464</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M60.2545,-176.9197C68.1865,-169.1293 79.5788,-157.9405 89.0712,-148.6176\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"91.7982,-150.845 96.4802,-141.3408 86.8932,-145.8509 91.7982,-150.845\"/>\n</g>\n<!-- 139661752257232 -->\n<g id=\"node5\" class=\"node\">\n<title>139661752257232</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"95,-257 6,-257 6,-238 95,-238 95,-257\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-245\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">PowBackward0</text>\n</g>\n<!-- 139661752257232&#45;&gt;139661752256272 -->\n<g id=\"edge3\" class=\"edge\">\n<title>139661752257232&#45;&gt;139661752256272</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M50.5,-237.9688C50.5,-229.5131 50.5,-216.8901 50.5,-206.2615\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"54.0001,-206.1656 50.5,-196.1656 47.0001,-206.1657 54.0001,-206.1656\"/>\n</g>\n<!-- 139661752257808 -->\n<g id=\"node6\" class=\"node\">\n<title>139661752257808</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"101,-318 0,-318 0,-299 101,-299 101,-318\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-306\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AccumulateGrad</text>\n</g>\n<!-- 139661752257808&#45;&gt;139661752257232 -->\n<g id=\"edge4\" class=\"edge\">\n<title>139661752257808&#45;&gt;139661752257232</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M50.5,-298.9688C50.5,-290.5131 50.5,-277.8901 50.5,-267.2615\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"54.0001,-267.1656 50.5,-257.1656 47.0001,-267.1657 54.0001,-267.1656\"/>\n</g>\n<!-- 139661776618032 -->\n<g id=\"node7\" class=\"node\">\n<title>139661776618032</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"80,-385 21,-385 21,-354 80,-354 80,-385\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-361\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (2, 2)</text>\n</g>\n<!-- 139661776618032&#45;&gt;139661752257808 -->\n<g id=\"edge5\" class=\"edge\">\n<title>139661776618032&#45;&gt;139661752257808</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M50.5,-353.791C50.5,-346.0249 50.5,-336.5706 50.5,-328.3129\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"54.0001,-328.0647 50.5,-318.0648 47.0001,-328.0648 54.0001,-328.0647\"/>\n</g>\n<!-- 139661752256016 -->\n<g id=\"node8\" class=\"node\">\n<title>139661752256016</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"214,-196 113,-196 113,-177 214,-177 214,-196\"/>\n<text text-anchor=\"middle\" x=\"163.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AccumulateGrad</text>\n</g>\n<!-- 139661752256016&#45;&gt;139661752256464 -->\n<g id=\"edge6\" class=\"edge\">\n<title>139661752256016&#45;&gt;139661752256464</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M153.5714,-176.9197C145.4169,-169.0514 133.6697,-157.7164 123.9508,-148.3385\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"126.3252,-145.7659 116.6987,-141.3408 121.4646,-150.8032 126.3252,-145.7659\"/>\n</g>\n<!-- 139661776618192 -->\n<g id=\"node9\" class=\"node\">\n<title>139661776618192</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"193,-263 134,-263 134,-232 193,-232 193,-263\"/>\n<text text-anchor=\"middle\" x=\"163.5\" y=\"-239\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (2, 2)</text>\n</g>\n<!-- 139661776618192&#45;&gt;139661752256016 -->\n<g id=\"edge7\" class=\"edge\">\n<title>139661776618192&#45;&gt;139661752256016</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M163.5,-231.791C163.5,-224.0249 163.5,-214.5706 163.5,-206.3129\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"167.0001,-206.0647 163.5,-196.0648 160.0001,-206.0648 167.0001,-206.0647\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20BBByj7Xzvd"
      },
      "source": [
        "Now we can compute the gradients with respect to `a` and `b` evaluated at the values of `a` and `b` that entered the computation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQvThv_8Wx8K"
      },
      "source": [
        "d.backward()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwljsNwsYO8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "075ecc17-8a01-4118-8031-d7fda93c7acc"
      },
      "source": [
        "print('gradient with respect to a:\\n {}'.format(a.grad))\n",
        "print('gradient with respect to b:\\n {}'.format(b.grad))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gradient with respect to a:\n",
            " tensor([[ 0.,  4.],\n",
            "        [ 8., 12.]], device='cuda:0')\n",
            "gradient with respect to b:\n",
            " tensor([[1., 1.],\n",
            "        [1., 1.]], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28K4hHRYgLkO"
      },
      "source": [
        "Make sure you can work out how these were computed and play around with modifying the inputs and the sequence of operations.  \n",
        "\n",
        "Congrats - you are in good shape to do some deep learning now!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znoIj87mnnf6"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}